{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name : tensor0D,tensor1D,tensor2D,tensor3D\n",
    ".dtype\n",
    ".shape gives rows and columns in tensor\n",
    "name.to (torch.float16)   Change Precision\n",
    "name.reshape\n",
    "name.view(3,2)\n",
    ".T (to get transpose)\n",
    ".matmul OR @ (Matrix Multiplication)\n",
    "\n",
    "\n",
    "#Feed Forward or Fully Connected Layer\n",
    "A linear layer multiplies the inputs with a weight matrix and adds a bias vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor0D = torch.tensor(1)\n",
    "tensor0D.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1D = torch.tensor([1,2,3])\n",
    "tensor1D.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "tensor2D = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor2D.dtype\n",
    "b = tensor2D.shape\n",
    "print(b)\n",
    "c = tensor2D.reshape(3,2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function Tensor.view>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3D = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "tensor3D.dtype\n",
    "prec = tensor3D.to(torch.float16)\n",
    "prec.dtype\n",
    "a = tensor3D.shape\n",
    "print(a)\n",
    "tensor3D.view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "t3d = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(t3d)\n",
    "Transpose = t3d.T\n",
    "print(Transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 29,  57],\n",
       "        [ 57, 146]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[2,4,3],[7,4,9]])\n",
    "B = torch.tensor([[5,6,7],[1,3,0]])\n",
    "C= A.T\n",
    "A.matmul(A.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0817]),)\n",
      "(tensor([-0.0898]),)\n",
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "y =torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2],requires_grad = True)  #By default Pytorch destroys computational graph after calculating the gradient to free the memory\n",
    "b1 = torch.tensor([0.0],requires_grad = True)\n",
    "z = x1*w1 + b1\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a,y)\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)  \n",
    "grad_L_b1 =grad(loss,b1,retain_graph=True) # if we set retain_graph = True , then we can reuse the graph\n",
    "\n",
    "print(grad_L_b1)\n",
    "print(grad_L_w1)\n",
    "\n",
    "\n",
    "# Pytorch provides .backwords on the loss\n",
    "# Pytorch will calculate the gradient of all the leaf nodes in the graph, which will be stored via tensors .grad\n",
    "\n",
    "\n",
    "loss.backward()\n",
    "print(w1.grad)\n",
    "print(b1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self,num_input,num_output):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input,30),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(30,20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(20,num_output),\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(50,3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters () if p.requires_grad)\n",
    "print('Total number of trainable parameters:',num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feed Forward or Fully Connected Layer\n",
    "## A linear layer multiplies the inputs with a weight matrix and adds a bias vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print (model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n",
      "Parameter containing:\n",
      "tensor([-0.1250,  0.0513,  0.0366,  0.0075,  0.0509,  0.0545, -0.0393,  0.0924,\n",
      "        -0.1412, -0.1232, -0.1063,  0.0081, -0.1249,  0.0101, -0.0019, -0.1298,\n",
      "         0.1388, -0.0330,  0.1017,  0.1247, -0.0554, -0.0417,  0.1388,  0.0159,\n",
      "         0.1215,  0.0385,  0.0769, -0.1224, -0.0279,  0.0991],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.shape)\n",
    "print(model.layers[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use above code on different computer, the numers in matrix shown above will differ because the model weights are initialized with small random numbers, which are differnt each time we instantiate the network.\n",
    "In DL, initializing small model weights with small random numbers is desired to break symmetry during training. \n",
    "\n",
    "Therefore, we use random seed by using torch.manual_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = NeuralNetwork(50, 3)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Forward Pass\n",
    "It refers to calculating output tensors from input tensors. This involves passing the input data through all the NN Layers , starting from the input layer, through hidden layers, and finally to the output layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "X= torch.rand((1,50))\n",
    "out = model(X)\n",
    "out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " The <AddmmBackward0> part of grad_fn=<AddmmBackward0> specifies the operation that was performed. In this case, it is an Addmm operation. Addmm stands for matrix multiplication (mm) followed by an addition (Add)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When we want to use model for inference(for instance, making prediction) rather than training, then we are not required to keep track of gradient at that time we cab use torch.no_grad() context manager as shown below. It will save memory and computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out= model(X)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In Pytorch the model is coded that they return the output of last layer without passing them to a non linear activation function.\n",
    "\n",
    "If we havwe to calculate the class membership probabilities for our predictions , we have to call softmax function explicitly. As given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3113, 0.3934, 0.2952]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(X),dim = 1)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have to create efficient data loaders in Pytorch , which we can iterate over when training the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset: Used to instantiate objects that defines how each record is loaded\n",
    "Data Loaders: handles how the data is shuffled and assembled into batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1. Creating custom dataset of five training examples with two features each.\n",
    "\n",
    "X_train = torch.tensor([\n",
    "    [-1.2 , 3.1],\n",
    "    [-0.9 , 2.9],\n",
    "    [-0.5 , 2.6],\n",
    "    [2.3 , -1.1],\n",
    "    [2.7 , -1.5]\n",
    "])\n",
    "\n",
    "#2. Accompanying the X_tX_train we crate a tensor containing the corresponding \n",
    "#   class labels: 3 belong to class 0 and 2 belongs to class 1 \n",
    "\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "#3. Make a test set consisting two entries\n",
    "\n",
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6]\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. We create a custom ToyDataset class by subclassing from PyTorch's Dataset parent class\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_x,one_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "train_ds = ToyDataset(X_train,y_train)\n",
    "test_ds = ToyDataset(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Threee main component of custom dataset are:\n",
    "__init__ : In this we set up attributes that we can access later in __getitem__ & __len__           This can be file path, file objects, database connectors , and so on.\n",
    "__getitem__ : In this , we define instructions for returning exactly one item from dataset              via an index.\n",
    "__len__ : Contains instructions for retrieving the length of the dataset.\n",
    "\n",
    "X and y are placeholder for our tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        dataset = train_ds,\n",
    "        batch_size = 2,\n",
    "        shuffle = False,\n",
    "        num_workers = 0\n",
    ")\n",
    "\n",
    "\n",
    "test_ds = ToyDataset (X_test,y_test)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset = test_ds,\n",
    "        batch_size = 2,\n",
    "        shuffle = False,\n",
    "        num_workers =0\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([0, 0])\n",
      "Batch 2: tensor([[-0.5000,  2.6000],\n",
      "        [ 2.3000, -1.1000]]) tensor([0, 1])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx +1}:\", x,y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As we can see based on the output, the train_loader iterates over training dataset visiting training example exactly once.This is known as training epoch.\n",
    "It should be noted that we have set the batch size of 2 , but the 3rd batch contains only single example.It is because of the five training examples, which is not evenly distributed by 2.\n",
    "\n",
    "In practice , if we have a substantially smaller batch in training epoch, it can duistrub the coverage during training.To prevent this we can set drop_last = True, which will drop the last batch in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.7000, -1.5000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-1.2000,  3.1000]]) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset= train_ds,\n",
    "    batch_size= 2,\n",
    "    shuffle= True,\n",
    "    num_workers= 0,\n",
    "    drop_last = True\n",
    "    \n",
    ")\n",
    "\n",
    "for idx, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx +1 }:\", x, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_workers : It is crucial for parallelizing data loading and preprocessing. When we set num_workers = 0, the data loading will be done in main process and not in seperate worker processes.\n",
    "\n",
    "It can lead to significat slowdown during model training when we train larger network on GPU. This can be because instead of focusing solely on the processing of DL model, the CPU must also take time to load and preprocess data. As a result , the GPU can sit idle while waiting for the CPU to finish tasks.\n",
    "\n",
    "When num_worker process is set to a number greater then 0 than multiple work processes are launched to load data in parallel, freezing the main process to train the model and better utilizing system resources.\n",
    "\n",
    "Issue: Setting num_workers to greater than 0 can sometimes lead to issues related to the sharing of resources between different processes, resulting in errors or notebook crashes. \n",
    "\n",
    "\n",
    "Optimal setting dor num_workers depends on hardware, datasets and the code used for loading the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Duplicate\n",
    "\n",
    "\n",
    "import torch\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self,num_input,num_output):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input,30),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(30,20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(20,num_output),\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  001/003| Batch 000/002 | Train/Val Loss:   0.75\n",
      "Epoch:  001/003| Batch 001/002 | Train/Val Loss:   0.65\n",
      "Epoch:  002/003| Batch 000/002 | Train/Val Loss:   0.44\n",
      "Epoch:  002/003| Batch 001/002 | Train/Val Loss:   0.13\n",
      "Epoch:  003/003| Batch 000/002 | Train/Val Loss:   0.03\n",
      "Epoch:  003/003| Batch 001/002 | Train/Val Loss:   0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F \n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_input=2, num_output=2)\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.5)\n",
    "\n",
    "\n",
    "num_epoch = 3\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    for batch_idx , (features, labels) in enumerate (train_loader):\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits , labels) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch:  {epoch +1:03d}/{num_epoch:03d}\" \n",
    "              f\"| Batch {batch_idx:03d}/{len(train_loader):03d}\" \n",
    "              f\" | Train/Val Loss:  {loss : .2f}\"  )\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8569, -4.1618],\n",
       "        [ 2.5382, -3.7548],\n",
       "        [ 2.0944, -3.1820],\n",
       "        [-1.4814,  1.4816],\n",
       "        [-1.7176,  1.7342]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9991,     0.0009],\n",
      "        [    0.9982,     0.0018],\n",
      "        [    0.9949,     0.0051],\n",
      "        [    0.0491,     0.9509],\n",
      "        [    0.0307,     0.9693]])\n"
     ]
    }
   ],
   "source": [
    "# To obtain the class membership probabilities we can use\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(outputs, dim= 1)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can cover this probability values into class labels using argmax function, it will return the index position of the highest value in each row if we set dim = 1 \n",
    "\n",
    "Note:\n",
    "if dim = 1 highest value in each row\n",
    "if dim = 0 highest value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim = 1) # we can directly apply outputs instead of probas\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verification\n",
    "\n",
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate number of currect prediction\n",
    "\n",
    "torch.sum(predictions == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To generalize prediction accuracy \n",
    "\n",
    "\n",
    "def compute_accuracy (model,dataloader):\n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for  idx , (features, labels) in enumerate (dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model (features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim =1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return (correct/total_examples).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above defined function iterate over a data loader to compute the number and fraction of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy (model , train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy (model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork (2,2)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only = True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The torch.load(\"model.pth\") function reads the file \"model.pth\" and reconstructs the Python dictionary object containing the model’s parameters while model.load_state_dict() applies these parameters to the model, effectively restoring its learned state from when we saved it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
